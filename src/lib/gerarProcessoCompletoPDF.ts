// @ts-nocheck - Tabelas podem n√£o existir no schema atual
import { PDFDocument } from "pdf-lib";
import { supabase } from "@/integrations/supabase/client";

interface ProcessoCompletoResult {
  url: string;
  filename: string;
}

export const gerarProcessoCompletoPDF = async (
  cotacaoId: string,
  numeroProcesso: string
): Promise<ProcessoCompletoResult> => {
  console.log(`Iniciando gera√ß√£o do processo completo para cota√ß√£o ${cotacaoId}...`);
  
  // Criar PDF final que ir√° conter todos os documentos mesclados
  const pdfFinal = await PDFDocument.create();

  try {
    // 1. Buscar anexos do processo (CAPA, REQUISI√á√ÉO, AUTORIZA√á√ÉO, TERMO DE REFER√äNCIA)
    const { data: cotacao, error: cotacaoError } = await supabase
      .from("cotacoes_precos")
      .select("processo_compra_id")
      .eq("id", cotacaoId)
      .single();

    if (cotacaoError) {
      console.error("Erro ao buscar cota√ß√£o:", cotacaoError);
      throw cotacaoError;
    }

    console.log(`Cota√ß√£o encontrada. Processo ID: ${cotacao?.processo_compra_id}`);

    if (cotacao?.processo_compra_id) {
      const { data: anexos, error: anexosError } = await supabase
        .from("anexos_processo_compra")
        .select("*")
        .eq("processo_compra_id", cotacao.processo_compra_id)
        .order("data_upload", { ascending: true });

      if (anexosError) {
        console.error("Erro ao buscar anexos:", anexosError);
      }

      console.log(`Anexos do processo encontrados: ${anexos?.length || 0}`);

      if (anexos && anexos.length > 0) {
        console.log(`üìÑ Mesclando ${anexos.length} documentos iniciais do processo...`);
        for (const anexo of anexos) {
          try {
            // Verificar se √© PDF
            if (!anexo.nome_arquivo.toLowerCase().endsWith('.pdf')) {
              console.log(`  ‚ö†Ô∏è AVISO: ${anexo.nome_arquivo} n√£o √© PDF. Apenas PDFs podem ser mesclados.`);
              continue;
            }
            
            console.log(`  Buscando: ${anexo.tipo_anexo} - ${anexo.nome_arquivo}`);
            console.log(`  Storage path: ${anexo.url_arquivo}`);
            
            // url_arquivo j√° √© o storage path, n√£o precisa extrair
            const { data: signedUrlData, error: signedError } = await supabase.storage
              .from('processo-anexos')
              .createSignedUrl(anexo.url_arquivo, 60);
            
            if (signedError || !signedUrlData) {
              console.error(`  ‚úó Erro ao gerar URL assinada: ${signedError?.message}`);
              continue;
            }
            
            const response = await fetch(signedUrlData.signedUrl);
            if (response.ok) {
              const arrayBuffer = await response.arrayBuffer();
              const pdfDoc = await PDFDocument.load(arrayBuffer);
              const copiedPages = await pdfFinal.copyPages(pdfDoc, pdfDoc.getPageIndices());
              copiedPages.forEach((page) => pdfFinal.addPage(page));
              console.log(`  ‚úì Mesclado: ${anexo.tipo_anexo} (${copiedPages.length} p√°ginas)`);
            } else {
              console.error(`  ‚úó Erro HTTP ${response.status} ao buscar ${anexo.nome_arquivo}`);
            }
          } catch (error) {
            console.error(`  ‚úó Erro ao mesclar ${anexo.nome_arquivo}:`, error);
          }
        }
      } else {
        console.log("‚ö†Ô∏è Nenhum anexo do processo encontrado");
      }
    }

    // 2. Buscar e-mails enviados aos fornecedores
    const { data: emails, error: emailsError } = await supabase
      .from("emails_cotacao_anexados")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("data_upload", { ascending: true });

    if (emailsError) {
      console.error("Erro ao buscar emails:", emailsError);
    }

    console.log(`E-mails encontrados: ${emails?.length || 0}`);

    if (emails && emails.length > 0) {
      console.log(`üìß Mesclando ${emails.length} e-mails enviados aos fornecedores...`);
      for (const email of emails) {
        try {
          console.log(`  Buscando: ${email.nome_arquivo}`);
          const response = await fetch(email.url_arquivo);
          if (response.ok) {
            const arrayBuffer = await response.arrayBuffer();
            const pdfDoc = await PDFDocument.load(arrayBuffer);
            const copiedPages = await pdfFinal.copyPages(pdfDoc, pdfDoc.getPageIndices());
            copiedPages.forEach((page) => pdfFinal.addPage(page));
            console.log(`  ‚úì Mesclado: ${email.nome_arquivo} (${copiedPages.length} p√°ginas)`);
          } else {
            console.error(`  ‚úó Erro HTTP ${response.status} ao buscar ${email.nome_arquivo}`);
          }
        } catch (error) {
          console.error(`  ‚úó Erro ao mesclar ${email.nome_arquivo}:`, error);
        }
      }
    } else {
      console.log("‚ö†Ô∏è Nenhum e-mail encontrado");
    }

    // 3. Preparar array para ordena√ß√£o cronol√≥gica de TODOS os documentos
    interface DocumentoOrdenado {
      tipo: string;
      data: string;
      nome: string;
      storagePath?: string;
      url?: string;
      bucket: string;
      fornecedor?: string;
    }
    
    const documentosOrdenados: DocumentoOrdenado[] = [];

    // 3a. Buscar propostas dos fornecedores e adicionar ao array cronol√≥gico
    const { data: respostas, error: respostasError } = await supabase
      .from("cotacao_respostas_fornecedor")
      .select("id, data_envio_resposta, fornecedores(razao_social)")
      .eq("cotacao_id", cotacaoId)
      .order("data_envio_resposta", { ascending: true });

    if (respostasError) {
      console.error("Erro ao buscar respostas:", respostasError);
    }

    console.log(`Respostas de fornecedores encontradas: ${respostas?.length || 0}`);

    if (respostas && respostas.length > 0) {
      for (const resposta of respostas) {
        const { data: anexosFornecedor, error: anexosFornError } = await supabase
          .from("anexos_cotacao_fornecedor")
          .select("*")
          .eq("cotacao_resposta_fornecedor_id", resposta.id)
          .order("data_upload", { ascending: true });

        if (anexosFornError) {
          console.error(`  Erro ao buscar anexos do fornecedor:`, anexosFornError);
        }

        const razaoSocial = (resposta.fornecedores as any)?.razao_social || 'Fornecedor';

        if (anexosFornecedor && anexosFornecedor.length > 0) {
          for (const anexo of anexosFornecedor) {
            // Verificar se √© PDF
            if (!anexo.nome_arquivo.toLowerCase().endsWith('.pdf')) {
              console.log(`    ‚ö†Ô∏è AVISO: ${anexo.nome_arquivo} n√£o √© PDF. Apenas PDFs podem ser mesclados.`);
              continue;
            }
            
            documentosOrdenados.push({
              tipo: "Proposta Fornecedor",
              data: anexo.data_upload || resposta.data_envio_resposta,
              nome: `${razaoSocial} - ${anexo.nome_arquivo}`,
              storagePath: anexo.url_arquivo,
              bucket: "processo-anexos",
              fornecedor: razaoSocial
            });
          }
        }
      }
    }

    // 4. Buscar TODAS as planilhas consolidadas
    const { data: planilhas, error: planilhasError } = await supabase
      .from("planilhas_consolidadas")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("data_geracao", { ascending: true });

    if (planilhasError) {
      console.error("Erro ao buscar planilhas:", planilhasError);
    }

    console.log(`Planilhas consolidadas encontradas: ${planilhas?.length || 0}`);
    
    if (planilhas && planilhas.length > 0) {
      planilhas.forEach(planilha => {
        documentosOrdenados.push({
          tipo: "Planilha Consolidada",
          data: planilha.data_geracao,
          nome: planilha.nome_arquivo,
          storagePath: planilha.url_arquivo,
          bucket: "processo-anexos"
        });
      });
    }

    // 5. Buscar TODOS os encaminhamentos ao compliance
    const { data: encaminhamentos, error: encaminhamentosError } = await supabase
      .from("encaminhamentos_processo")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("created_at", { ascending: true });

    if (encaminhamentosError) {
      console.error("Erro ao buscar encaminhamentos:", encaminhamentosError);
    }

    console.log(`Encaminhamentos encontrados: ${encaminhamentos?.length || 0}`);
    
    if (encaminhamentos && encaminhamentos.length > 0) {
      encaminhamentos.forEach(enc => {
        documentosOrdenados.push({
          tipo: "Encaminhamento ao Compliance",
          data: enc.created_at,
          nome: `Encaminhamento ${enc.protocolo}`,
          storagePath: enc.storage_path,
          bucket: "processo-anexos"
        });
      });
    }

    // 6. Buscar TODAS as an√°lises de compliance
    const { data: analises, error: analisesError } = await supabase
      .from("analises_compliance")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("data_analise", { ascending: true });

    if (analisesError) {
      console.error("Erro ao buscar an√°lises:", analisesError);
    }

    console.log(`An√°lises de compliance encontradas: ${analises?.length || 0}`);
    
    if (analises && analises.length > 0) {
      analises.forEach(analise => {
        if (analise.url_documento) {
          documentosOrdenados.push({
            tipo: "An√°lise de Compliance",
            data: analise.data_analise || analise.created_at,
            nome: analise.nome_arquivo || `An√°lise ${analise.protocolo}`,
            url: analise.url_documento,
            bucket: "documents"
          });
        }
      });
    }

    // 7. Buscar TODOS os relat√≥rios finais
    const { data: relatorios, error: relatoriosError } = await supabase
      .from("relatorios_finais")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("data_geracao", { ascending: true });

    if (relatoriosError) {
      console.error("Erro ao buscar relat√≥rios:", relatoriosError);
    }

    console.log(`Relat√≥rios finais encontrados: ${relatorios?.length || 0}`);

    // 8. Buscar TODAS as autoriza√ß√µes
    const { data: autorizacoes, error: autorizacoesError } = await supabase
      .from("autorizacoes_processo")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("data_geracao", { ascending: true });

    if (autorizacoesError) {
      console.error("Erro ao buscar autoriza√ß√µes:", autorizacoesError);
    }

    console.log(`Autoriza√ß√µes encontradas: ${autorizacoes?.length || 0}`);

    // 9. Ordenar TODOS os documentos normais por data cronol√≥gica
    documentosOrdenados.sort((a, b) => new Date(a.data).getTime() - new Date(b.data).getTime());

    console.log(`\nüìÖ Total de documentos cronol√≥gicos ordenados: ${documentosOrdenados.length}`);

    // 10. Encontrar a data do √∫ltimo documento cronol√≥gico (geralmente √∫ltima an√°lise de compliance)
    const ultimaDataCronologica = documentosOrdenados.length > 0
      ? documentosOrdenados[documentosOrdenados.length - 1].data
      : new Date().toISOString();

    console.log(`üìÜ √öltima data cronol√≥gica: ${new Date(ultimaDataCronologica).toLocaleString('pt-BR')}`);

    // 11. Buscar e adicionar documentos dos fornecedores aprovados (snapshot) AP√ìS √∫ltima data
    const { data: documentosSnapshot, error: snapshotError } = await supabase
      .from("documentos_processo_finalizado")
      .select("*")
      .eq("cotacao_id", cotacaoId)
      .order("data_snapshot", { ascending: true });

    if (snapshotError) {
      console.error("Erro ao buscar documentos snapshot:", snapshotError);
    }

    console.log(`üìÑ Documentos snapshot encontrados: ${documentosSnapshot?.length || 0}`);

    if (documentosSnapshot && documentosSnapshot.length > 0) {
      // Adicionar 1 segundo √† √∫ltima data para garantir que os snapshots venham logo ap√≥s
      const dataSnapshot = new Date(new Date(ultimaDataCronologica).getTime() + 1000).toISOString();
      
      // Usar Set para garantir que cada documento seja adicionado apenas uma vez baseado em seu ID √∫nico
      const idsAdicionados = new Set<string>();
      
      documentosSnapshot.forEach(doc => {
        if (!idsAdicionados.has(doc.id)) {
          idsAdicionados.add(doc.id);
          documentosOrdenados.push({
            tipo: "Documento Fornecedor Aprovado",
            data: dataSnapshot,
            nome: `${doc.tipo_documento} - ${doc.nome_arquivo}`,
            url: doc.url_arquivo,
            bucket: "processo-anexos"
          });
        }
      });
    }

    // 12. Adicionar relat√≥rios finais AP√ìS documentos dos fornecedores
    if (relatorios && relatorios.length > 0) {
      // Adicionar 2 segundos √† √∫ltima data
      const dataRelatorios = new Date(new Date(ultimaDataCronologica).getTime() + 2000).toISOString();
      
      relatorios.forEach(relatorio => {
        // Extrair storage path da URL (pode ser signed URL ou public URL)
        let storagePath = relatorio.url_arquivo;
        if (storagePath.includes('/storage/v1/object/')) {
          // √â uma URL do Supabase Storage, extrair o path
          const match = storagePath.match(/\/processo-anexos\/(.+?)(\?|$)/);
          if (match) {
            storagePath = `relatorios-finais/${match[1].split('?')[0]}`;
          }
        }
        
        documentosOrdenados.push({
          tipo: "Relat√≥rio Final",
          data: dataRelatorios,
          nome: relatorio.nome_arquivo,
          url: relatorio.url_arquivo, // Usar URL direta
          bucket: "processo-anexos"
        });
      });
    }

    // 13. Adicionar autoriza√ß√µes AP√ìS relat√≥rios finais
    if (autorizacoes && autorizacoes.length > 0) {
      // Adicionar 3 segundos √† √∫ltima data
      const dataAutorizacoes = new Date(new Date(ultimaDataCronologica).getTime() + 3000).toISOString();
      
      autorizacoes.forEach(aut => {
        documentosOrdenados.push({
          tipo: `Autoriza√ß√£o (${aut.tipo_autorizacao})`,
          data: dataAutorizacoes,
          nome: aut.nome_arquivo,
          url: aut.url_arquivo, // Usar URL direta (j√° √© signed URL v√°lida)
          bucket: "processo-anexos"
        });
      });
    }

    console.log(`\nüìÖ Total de documentos a serem mesclados em ordem cronol√≥gica: ${documentosOrdenados.length}`);

    // 12. Mesclar todos os documentos na ordem cronol√≥gica
    if (documentosOrdenados.length > 0) {
      console.log("üìã Mesclando documentos em ordem cronol√≥gica...\n");
      
      for (const doc of documentosOrdenados) {
        try {
          console.log(`  [${new Date(doc.data).toLocaleString('pt-BR')}] ${doc.tipo}: ${doc.nome}`);
          
          let pdfUrl: string | null = null;

          // Se tem URL p√∫blica (an√°lises), usar diretamente
          if (doc.url) {
            pdfUrl = doc.url;
          }
          // Se tem storage path, gerar signed URL
          else if (doc.storagePath) {
            const { data: signedUrlData, error: signedError } = await supabase.storage
              .from(doc.bucket)
              .createSignedUrl(doc.storagePath, 60);
            
            if (signedError || !signedUrlData) {
              console.error(`    ‚úó Erro ao gerar URL assinada: ${signedError?.message}`);
              continue;
            }
            
            pdfUrl = signedUrlData.signedUrl;
          }

          if (pdfUrl) {
            try {
              const response = await fetch(pdfUrl);
              if (response.ok) {
                const arrayBuffer = await response.arrayBuffer();
                const pdfDoc = await PDFDocument.load(arrayBuffer);
                const copiedPages = await pdfFinal.copyPages(pdfDoc, pdfDoc.getPageIndices());
                copiedPages.forEach((page) => pdfFinal.addPage(page));
                console.log(`    ‚úì Mesclado (${copiedPages.length} p√°ginas)`);
              } else {
                console.error(`    ‚úó Erro HTTP ${response.status}`);
              }
            } catch (fetchError) {
              console.error(`    ‚úó Erro ao buscar arquivo:`, fetchError);
              
              // Se o storage path falhou, tentar buscar do bucket documents (para documentos p√∫blicos)
              if (doc.storagePath && doc.bucket === 'processo-anexos') {
                try {
                  console.log(`    üîÑ Tentando buscar do bucket documents...`);
                  const { data: publicUrlData } = supabase.storage
                    .from('documents')
                    .getPublicUrl(doc.storagePath);
                  
                  if (publicUrlData?.publicUrl) {
                    const retryResponse = await fetch(publicUrlData.publicUrl);
                    if (retryResponse.ok) {
                      const arrayBuffer = await retryResponse.arrayBuffer();
                      const pdfDoc = await PDFDocument.load(arrayBuffer);
                      const copiedPages = await pdfFinal.copyPages(pdfDoc, pdfDoc.getPageIndices());
                      copiedPages.forEach((page) => pdfFinal.addPage(page));
                      console.log(`    ‚úì Mesclado do bucket documents (${copiedPages.length} p√°ginas)`);
                    }
                  }
                } catch (retryError) {
                  console.error(`    ‚úó Tamb√©m falhou ao buscar do bucket documents:`, retryError);
                }
              }
            }
          }
        } catch (error) {
          console.error(`    ‚úó Erro ao mesclar documento:`, error);
        }
      }
    } else {
      console.log("‚ö†Ô∏è Nenhum documento adicional encontrado para mesclar");
    }

    // Verificar se h√° p√°ginas no PDF final
    const totalPaginas = pdfFinal.getPageCount();
    console.log(`\nüìë Total de p√°ginas mescladas: ${totalPaginas}`);

    if (totalPaginas === 0) {
      throw new Error("Nenhum documento foi encontrado para mesclar. Verifique se h√° documentos anexados ao processo.");
    }

    // Salvar PDF mesclado
    console.log("\nüíæ Salvando PDF mesclado...");
    const pdfBytes = await pdfFinal.save();
    const blob = new Blob([pdfBytes], { type: "application/pdf" });
    
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    const filename = `processo_completo_${numeroProcesso.replace(/\//g, "-")}_${timestamp}.pdf`;
    const storagePath = `processos/${filename}`;

    const { error: uploadError } = await supabase.storage
      .from("documents")
      .upload(storagePath, blob, {
        contentType: "application/pdf",
        upsert: false,
      });

    if (uploadError) {
      console.error("‚ùå Erro ao fazer upload:", uploadError);
      throw new Error("Erro ao salvar processo completo");
    }

    const { data: urlData } = supabase.storage
      .from("documents")
      .getPublicUrl(storagePath);

    console.log("‚úÖ Processo completo gerado com sucesso!");
    console.log(`   Arquivo: ${filename}`);
    console.log(`   P√°ginas: ${totalPaginas}`);
    
    return {
      url: urlData.publicUrl,
      filename,
    };
  } catch (error) {
    console.error("‚ùå Erro ao gerar processo completo:", error);
    throw error;
  }
};
